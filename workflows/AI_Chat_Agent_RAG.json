{
  "name": "AI Chat Agent with RAG Memory",
  "nodes": [
    {
      "parameters": {
        "httpMethod": "POST",
        "path": "ai-chat",
        "responseMode": "responseNode",
        "options": {}
      },
      "id": "webhook-node",
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [240, 300],
      "webhookId": "ai-chat-agent"
    },
    {
      "parameters": {
        "jsCode": "// Extract user message and context\nconst body = $input.item.json.body || $input.item.json;\nconst userMessage = body.message || body.query || \"\";\nconst context = body.context || \"\";\nconst conversationId = body.conversationId || \"default\";\n\nreturn {\n  userMessage: userMessage,\n  context: context,\n  conversationId: conversationId,\n  timestamp: new Date().toISOString()\n};"
      },
      "id": "extract-input",
      "name": "Extract Input",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [460, 300]
    },
    {
      "parameters": {
        "jsCode": "// Build the prompt with context\nconst userMessage = $input.item.json.userMessage;\nconst context = $input.item.json.context;\n\nlet systemPrompt = `You are a helpful AI assistant with access to long-term memory and context.\n\nYou can remember past conversations and provide context-aware responses.\nBe friendly, helpful, and informative.`;\n\nif (context && context.trim() !== \"\") {\n  systemPrompt += `\\n\\n## Relevant Context from Memory:\\n${context}`;\n}\n\nconst prompt = {\n  system: systemPrompt,\n  user: userMessage\n};\n\nreturn {\n  ...prompt,\n  fullPrompt: `${systemPrompt}\\n\\nUser: ${userMessage}\\n\\nAssistant:`\n};"
      },
      "id": "build-prompt",
      "name": "Build Prompt with Context",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [680, 300]
    },
    {
      "parameters": {
        "resource": "text",
        "operation": "message",
        "model": "gpt-4",
        "messages": {
          "values": [
            {
              "role": "system",
              "content": "={{ $json.system }}"
            },
            {
              "role": "user",
              "content": "={{ $json.user }}"
            }
          ]
        },
        "options": {
          "temperature": 0.7,
          "maxTokens": 1000
        }
      },
      "id": "openai-chat",
      "name": "OpenAI Chat",
      "type": "n8n-nodes-base.openAi",
      "typeVersion": 1,
      "position": [900, 300],
      "credentials": {
        "openAiApi": {
          "id": "1",
          "name": "OpenAI API"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Format the response\nconst response = $input.item.json;\nconst aiMessage = response.message?.content || response.choices?.[0]?.message?.content || \"\";\nconst userMessage = $node[\"Extract Input\"].json.userMessage;\nconst conversationId = $node[\"Extract Input\"].json.conversationId;\n\nreturn {\n  success: true,\n  conversationId: conversationId,\n  query: userMessage,\n  response: aiMessage,\n  timestamp: new Date().toISOString(),\n  model: \"gpt-4\",\n  metadata: {\n    hasContext: ($node[\"Extract Input\"].json.context || \"\").length > 0\n  }\n};"
      },
      "id": "format-response",
      "name": "Format Response",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1120, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "id": "respond-webhook",
      "name": "Respond to Webhook",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [1340, 300]
    },
    {
      "parameters": {
        "jsCode": "// Store conversation in memory (you can connect this to a database)\nconst data = $input.item.json;\n\n// This is a placeholder - connect to your database or vector store\n// For now, just pass the data through\nreturn data;"
      },
      "id": "store-memory",
      "name": "Store in Memory",
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [1120, 460]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Extract Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Input": {
      "main": [
        [
          {
            "node": "Build Prompt with Context",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Build Prompt with Context": {
      "main": [
        [
          {
            "node": "OpenAI Chat",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI Chat": {
      "main": [
        [
          {
            "node": "Format Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Format Response": {
      "main": [
        [
          {
            "node": "Respond to Webhook",
            "type": "main",
            "index": 0
          },
          {
            "node": "Store in Memory",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "1",
  "id": "ai-chat-rag-workflow",
  "meta": {
    "instanceId": "n8n-instance"
  },
  "tags": []
}
