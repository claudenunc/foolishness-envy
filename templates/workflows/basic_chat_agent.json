{
  "name": "Basic Chat Agent",
  "description": "Simple chat agent with memory retrieval",
  "nodes": [
    {
      "parameters": {},
      "name": "Webhook",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [250, 300],
      "webhookId": "chat-agent"
    },
    {
      "parameters": {
        "operation": "text",
        "options": {
          "temperature": 0.7,
          "maxTokens": 1000
        }
      },
      "name": "OpenAI",
      "type": "n8n-nodes-base.openAi",
      "typeVersion": 1,
      "position": [650, 300]
    },
    {
      "parameters": {
        "respondWith": "json",
        "responseBody": "={{ $json }}",
        "options": {}
      },
      "name": "Respond",
      "type": "n8n-nodes-base.respondToWebhook",
      "typeVersion": 1,
      "position": [850, 300]
    },
    {
      "parameters": {
        "functionCode": "// Get context from memory\nconst context = $input.item.json.context || '';\nconst query = $input.item.json.query || '';\n\n// Build prompt with context\nconst prompt = context \n  ? `Context:\\n${context}\\n\\nUser Query: ${query}\\n\\nResponse:`\n  : `User Query: ${query}\\n\\nResponse:`;\n\nreturn [{\n  json: {\n    prompt: prompt,\n    query: query\n  }\n}];"
      },
      "name": "Prepare Prompt",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [450, 300]
    }
  ],
  "connections": {
    "Webhook": {
      "main": [
        [
          {
            "node": "Prepare Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Prompt": {
      "main": [
        [
          {
            "node": "OpenAI",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenAI": {
      "main": [
        [
          {
            "node": "Respond",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  }
}
